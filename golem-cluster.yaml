cluster_name: golem-cluster

# The maximum number of workers the cluster will have at any given time
max_workers: 10
# The number of minutes that need to pass before an idle worker node is removed by the Autoscaler
idle_timeout_minutes: 5

# The cloud provider-specific configuration properties.
provider:
  type: "external"
  use_internal_ips: true
  module: "golem_ray.provider.node_provider.GolemNodeProvider"
  parameters:
    # Url of golem webserver that has connection with golem network
    golem_ray_url: "http://localhost:8080"
    # check available versions at https://registry.golem.network/explore/loop/golem-ray
    # if not provided, image_tag will be resolved based on currently used
    # or image_hash may be provided
    # version of python and ray
#    image_tag: "py3.10.6-ray2.6.1-lib"
    image_hash: "9ef14614721f9655d65d9bc5dbf64038b5e21721a15b4686e051b9b2"
    # Golem network on which we will launch nodes
    network: "goerli"
    # Maximum amount of GML that's going to be spent
    budget: 1

# The files or directories to copy to the head and worker nodes
file_mounts:
  {
  }

# Tells the autoscaler the allowed node types and the resources they provide
available_node_types:
  ray.head.default:
    # The minimum number of worker nodes of this type to launch
    min_workers: 0
    # The maximum number of worker nodes of this type to launch
    max_workers: 1
    # The node type's CPU and GPU resources
    resources: {"CPU": 1}
    node_config:
      kind: Node
  ray.worker.default:
    min_workers: 3
    max_workers: 10
    resources: {"CPU": 1}
    node_config:
      kind: Node

# List of commands that will be run before `setup_commands`
initialization_commands: []
# List of shell commands to run to set up nodes
setup_commands: [
  "echo 'export SERVER_BASE_URL=http://proxy.dev.golem.network:3010' >> ~/.bashrc",
]

# Custom commands that will be run on the head node after common setup.
head_setup_commands: []
# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands: [
  "ray start --head --node-ip-address 192.168.0.3 --dashboard-port 8266 --autoscaling-config=~/ray_bootstrap_config.yaml",
]
# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands: [
  "ray start --address 192.168.0.3:6379 --dashboard-port 8266 --autoscaling-config=$BOOTSTRAP_CONFIG_FILE",
]
# Authentication credentials that Ray will use to launch nodes
auth:
  ssh_user: 'root'
#  ssh_private_key: '~/.ssh/id_rsa'

# A list of paths to the files or directories to copy from the head node to the worker nodes
cluster_synced_files: []
